--- a/main.py
+++ b/main.py
@@ -1,7 +1,7 @@
 from __future__ import annotations
 
-import json, os, re, time, random, hashlib, logging, sqlite3, threading
-from collections import Counter
+import json, os, re, time, random, hashlib, logging, sqlite3, threading, contextvars
+from collections import Counter, deque
 from dataclasses import dataclass
 from typing import Optional
 import requests
@@ -55,6 +55,382 @@
 
 # If tweet includes a cashtag, allow 1 witty line (still no emojis/hashtags)
 
 PRO_KOL_ALLOW_WIT = os.getenv("PRO_KOL_ALLOW_WIT", "1").strip() != "0"
+
+# ------------------------------------------------------------------------------
+# Research-grade add-ons (best-effort; never blocks generation)
+# ------------------------------------------------------------------------------
+ENABLE_THREAD_CONTEXT = os.getenv("ENABLE_THREAD_CONTEXT", "1").strip() == "1"
+ENABLE_RESEARCH = os.getenv("ENABLE_RESEARCH", "1").strip() == "1"
+ENABLE_COINGECKO = os.getenv("ENABLE_COINGECKO", "0").strip() == "1"
+COINGECKO_DEMO_KEY = os.getenv("COINGECKO_DEMO_KEY") or os.getenv("COINGECKO_API_KEY") or ""
+RESEARCH_CACHE_TTL_SEC = int(os.getenv("RESEARCH_CACHE_TTL_SEC", "900") or "900")
+
+# Request-scoped context storage
+REQUEST_THREAD_CTX: contextvars.ContextVar[dict] = contextvars.ContextVar("REQUEST_THREAD_CTX", default={})
+REQUEST_RESEARCH_CTX: contextvars.ContextVar[dict] = contextvars.ContextVar("REQUEST_RESEARCH_CTX", default={})
+REQUEST_VOICE: contextvars.ContextVar[dict | None] = contextvars.ContextVar("REQUEST_VOICE", default=None)
+
+# Caches + circuit breakers
+_RESEARCH_CACHE: dict[str, tuple[float, object]] = {}
+_RESEARCH_CACHE_LOCK = threading.Lock()
+_COINGECKO_DISABLED_UNTIL_TS = 0.0
+_RECENT_VOICES = deque(maxlen=4)
+
+DEFILLAMA_BASE = "https://api.llama.fi"
+COINGECKO_BASE = "https://api.coingecko.com/api/v3"
+
+_VX_ID_RE = re.compile(r"/status/(\d+)")
+_CASHTAG_RE = re.compile(r"\$[A-Za-z0-9_]{2,15}")
+_NUM_TOKEN_RE = re.compile(r"\d+(?:\.\d+)?")
+
+VOICE_CARDS: list[dict] = [
+    {"id": "trader", "brief": "CT trader energy: flow-aware, risk/reward, positioning. No hype.", "rules": "Talk incentives/positioning; ask sharp questions; no shilling."},
+    {"id": "builder", "brief": "Product builder: how it works, integrations, tradeoffs, execution.", "rules": "Concrete implementation notes; what could break; next steps."},
+    {"id": "researcher", "brief": "Researcher: precise, caveated, compares to baselines.", "rules": "Prefer 'seems/looks' unless in tweet/research; ask for metrics/links."},
+    {"id": "skeptic", "brief": "Skeptic: respectful but probing. Tests assumptions.", "rules": "Call out risks/incentives; ask 'what happens if…'."},
+    {"id": "curious_friend", "brief": "Curious friend: smart, warm, genuinely trying to understand.", "rules": "Short + specific curiosity; no fluff; grounded."},
+    {"id": "deadpan_meme", "brief": "Deadpan meme: dry one-liner that still fits the topic (no emojis).", "rules": "One clean punch; no cringe; stay relevant."},
+]
+
+def _cache_get(key: str, ttl_sec: int = RESEARCH_CACHE_TTL_SEC):
+    now = time.time()
+    with _RESEARCH_CACHE_LOCK:
+        hit = _RESEARCH_CACHE.get(key)
+        if not hit:
+            return None
+        ts, val = hit
+        if (now - ts) > ttl_sec:
+            _RESEARCH_CACHE.pop(key, None)
+            return None
+        return val
+
+def _cache_set(key: str, val: object) -> None:
+    with _RESEARCH_CACHE_LOCK:
+        _RESEARCH_CACHE[key] = (time.time(), val)
+
+def _extract_tweet_id(url: str) -> str | None:
+    m = _VX_ID_RE.search(url or "")
+    return m.group(1) if m else None
+
+def _compact(text: str, limit: int = 520) -> str:
+    text = normalize_ws(text or "")
+    return text if len(text) <= limit else (text[:limit-1].rstrip() + "…")
+
+def _vx_get_json(tweet_id: str, timeout_sec: float = 1.2) -> dict | None:
+    if not tweet_id:
+        return None
+    url = f"https://api.vxtwitter.com/Twitter/status/{tweet_id}"
+    try:
+        r = requests.get(url, timeout=timeout_sec, headers={"accept": "application/json"})
+        if r.status_code != 200:
+            return None
+        return r.json()
+    except Exception:
+        return None
+
+def _first_text(obj) -> str:
+    if not isinstance(obj, dict):
+        return ""
+    for k in ("text", "full_text", "tweet_text", "content"):
+        v = obj.get(k)
+        if isinstance(v, str) and v.strip():
+            return v.strip()
+    return ""
+
+def _pull_nested_text(d: dict, keys: list[str]) -> str:
+    for k in keys:
+        v = d.get(k)
+        if isinstance(v, dict):
+            txt = _first_text(v)
+            if txt:
+                return txt
+            for kk in ("tweet", "status", "data"):
+                if isinstance(v.get(kk), dict):
+                    txt = _first_text(v.get(kk))
+                    if txt:
+                        return txt
+    return ""
+
+def fetch_thread_context(tweet_url: str) -> dict:
+    """Best-effort quote/parent tweet context via VXTwitter."""
+    ctx: dict = {}
+    if not (ENABLE_THREAD_CONTEXT and tweet_url):
+        return ctx
+    tid = _extract_tweet_id(tweet_url)
+    j = _vx_get_json(tid) if tid else None
+    if not isinstance(j, dict):
+        return ctx
+    quoted = _pull_nested_text(j, ["quoted_tweet", "quotedTweet", "quoted_status", "quotedStatus", "quote", "qrt", "quoted"])
+    if quoted:
+        ctx["quoted_text"] = _compact(quoted, 520)
+    parent = _pull_nested_text(j, ["replying_to_tweet", "replyingToTweet", "replying_to", "replyingTo", "in_reply_to", "inReplyTo", "parent_tweet", "parentTweet"])
+    if parent:
+        ctx["parent_text"] = _compact(parent, 520)
+    return ctx
+
+def pick_voice(tweet_text: str) -> dict:
+    topic = detect_topic(tweet_text or "")
+    weights = {"trader": 1.0, "builder": 0.9, "researcher": 0.9, "skeptic": 0.9, "curious_friend": 0.8, "deadpan_meme": 0.35}
+    if topic in ("defi", "trading", "memecoin", "markets"):
+        weights["trader"] += 0.7
+        weights["skeptic"] += 0.2
+    if topic in ("builder", "product", "infra", "ai"):
+        weights["builder"] += 0.6
+        weights["researcher"] += 0.2
+    if topic in ("research", "macro"):
+        weights["researcher"] += 0.6
+        weights["skeptic"] += 0.3
+
+    for vid in list(_RECENT_VOICES):
+        if vid in weights:
+            weights[vid] = max(0.05, weights[vid] * 0.35)
+
+    ids = [c["id"] for c in VOICE_CARDS]
+    w = [max(0.0, float(weights.get(i, 0.1))) for i in ids]
+    if sum(w) <= 0:
+        w = [1.0] * len(ids)
+    chosen = random.choices(ids, weights=w, k=1)[0]
+    _RECENT_VOICES.append(chosen)
+    for c in VOICE_CARDS:
+        if c["id"] == chosen:
+            return c
+    return VOICE_CARDS[0]
+
+def _extract_cashtags(text: str) -> list[str]:
+    return _CASHTAG_RE.findall(text or "")
+
+def _extract_numbers(text: str) -> list[str]:
+    return _NUM_TOKEN_RE.findall(text or "")
+
+def _defillama_get_json(path: str, timeout_sec: float = 1.5):
+    url = f"{DEFILLAMA_BASE}{path}"
+    try:
+        r = requests.get(url, timeout=timeout_sec, headers={"accept": "application/json"})
+        if r.status_code != 200:
+            return None
+        return r.json()
+    except Exception:
+        return None
+
+def defillama_protocols() -> list[dict]:
+    cached = _cache_get("defillama:protocols", ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if isinstance(cached, list):
+        return cached
+    data = _defillama_get_json("/protocols", timeout_sec=1.5)
+    if isinstance(data, list):
+        _cache_set("defillama:protocols", data)
+        return data
+    return []
+
+def defillama_protocol(slug: str) -> dict | None:
+    if not slug:
+        return None
+    key = f"defillama:protocol:{slug}"
+    cached = _cache_get(key, ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if isinstance(cached, dict):
+        return cached
+    data = _defillama_get_json(f"/protocol/{slug}", timeout_sec=1.5)
+    if isinstance(data, dict):
+        _cache_set(key, data)
+        return data
+    return None
+
+def defillama_tvl(slug: str):
+    if not slug:
+        return None
+    key = f"defillama:tvl:{slug}"
+    cached = _cache_get(key, ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if cached is not None:
+        return cached
+    data = _defillama_get_json(f"/tvl/{slug}", timeout_sec=1.5)
+    if data is not None:
+        _cache_set(key, data)
+        return data
+    return None
+
+def _coin_gecko_disabled() -> bool:
+    return time.time() < _COINGECKO_DISABLED_UNTIL_TS
+
+def _coingecko_headers() -> dict:
+    h = {"accept": "application/json"}
+    if COINGECKO_DEMO_KEY:
+        h["x-cg-demo-api-key"] = COINGECKO_DEMO_KEY
+    return h
+
+def coingecko_search(query: str) -> dict | None:
+    global _COINGECKO_DISABLED_UNTIL_TS
+    if not (ENABLE_COINGECKO and query) or _coin_gecko_disabled():
+        return None
+    key = f"cg:search:{query.lower().strip()}"
+    cached = _cache_get(key, ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if isinstance(cached, dict):
+        return cached
+    try:
+        r = requests.get(f"{COINGECKO_BASE}/search", params={"query": query}, timeout=1.5, headers=_coingecko_headers())
+        if r.status_code == 429:
+            _COINGECKO_DISABLED_UNTIL_TS = time.time() + 900
+            return None
+        if r.status_code != 200:
+            return None
+        data = r.json()
+        if isinstance(data, dict):
+            _cache_set(key, data)
+            return data
+    except Exception:
+        return None
+    return None
+
+def coingecko_price(ids: str, vs: str = "usd") -> dict | None:
+    global _COINGECKO_DISABLED_UNTIL_TS
+    if not (ENABLE_COINGECKO and ids) or _coin_gecko_disabled():
+        return None
+    key = f"cg:price:{ids}:{vs}"
+    cached = _cache_get(key, ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if isinstance(cached, dict):
+        return cached
+    try:
+        r = requests.get(f"{COINGECKO_BASE}/simple/price", params={"ids": ids, "vs_currencies": vs}, timeout=1.5, headers=_coingecko_headers())
+        if r.status_code == 429:
+            _COINGECKO_DISABLED_UNTIL_TS = time.time() + 900
+            return None
+        if r.status_code != 200:
+            return None
+        data = r.json()
+        if isinstance(data, dict):
+            _cache_set(key, data)
+            return data
+    except Exception:
+        return None
+    return None
+
+def _norm_entity_key(kind: str, k: str) -> str:
+    k = (k or "").strip()
+    return k.lstrip("$").upper() if kind == "ticker" else k.lower()
+
+def entity_map_get(kind: str, k: str) -> str | None:
+    try:
+        nk = _norm_entity_key(kind, k)
+        if not nk:
+            return None
+        with get_conn() as c:
+            row = c.execute("SELECT slug FROM entity_map WHERE kind=? AND k=?", (kind, nk)).fetchone()
+        return row[0] if row else None
+    except Exception:
+        return None
+
+def entity_map_put(kind: str, k: str, slug: str) -> None:
+    try:
+        nk = _norm_entity_key(kind, k)
+        slug = (slug or "").strip()
+        if not (nk and slug):
+            return
+        with get_conn() as c:
+            c.execute("INSERT OR REPLACE INTO entity_map(kind, k, slug, updated_at) VALUES (?,?,?,?)", (kind, nk, slug, now_ts()))
+    except Exception:
+        pass
+
+def resolve_defillama_slug(tweet_text: str) -> str | None:
+    text = tweet_text or ""
+    tickers = _extract_cashtags(text)
+
+    for t in tickers:
+        slug = entity_map_get("ticker", t)
+        if slug:
+            return slug
+
+    # quick name memory
+    for nm in extract_keywords(text)[:6]:
+        slug = entity_map_get("name", nm)
+        if slug:
+            return slug
+
+    protos = defillama_protocols()
+    if not protos:
+        return None
+
+    # symbol match first
+    for t in tickers:
+        sym = t.lstrip("$").upper()
+        for p in protos:
+            ps = (p.get("symbol") or "").upper()
+            if ps and ps == sym:
+                return p.get("slug") or p.get("id") or p.get("name")
+
+    low = text.lower()
+    for p in protos:
+        name = (p.get("name") or "")
+        slug = (p.get("slug") or p.get("id") or "")
+        if name and name.lower() in low and slug:
+            return slug
+    return None
+
+def research_context_for_tweet(tweet_text: str) -> dict:
+    """Fetch once per request (best-effort + cached). Never blocks generator."""
+    if not ENABLE_RESEARCH:
+        return {}
+    key = "research:" + sha256(_normalize_for_memory(tweet_text))[:24]
+    cached = _cache_get(key, ttl_sec=RESEARCH_CACHE_TTL_SEC)
+    if isinstance(cached, dict):
+        return cached
+
+    ctx: dict = {}
+    try:
+        slug = resolve_defillama_slug(tweet_text)
+        if slug:
+            proto = defillama_protocol(slug) or {}
+            ctx["defillama"] = {
+                "slug": slug,
+                "name": proto.get("name"),
+                "symbol": proto.get("symbol"),
+                "category": proto.get("category"),
+                "tvl": proto.get("tvl"),
+                "chains": proto.get("chains"),
+                "url": proto.get("url"),
+            }
+            # entity memory
+            for t in _extract_cashtags(tweet_text):
+                entity_map_put("ticker", t, slug)
+            if proto.get("name"):
+                entity_map_put("name", str(proto.get("name")), slug)
+
+            series = defillama_tvl(slug)
+            if series is not None:
+                ctx["defillama_tvl_series"] = series
+
+            # optional CoinGecko enrichment
+            if ENABLE_COINGECKO:
+                q = (proto.get("symbol") or proto.get("name") or "").strip()
+                if q:
+                    sr = coingecko_search(q)
+                    if isinstance(sr, dict):
+                        coins = sr.get("coins") or []
+                        if coins:
+                            cg_id = coins[0].get("id")
+                            if cg_id:
+                                price = coingecko_price(cg_id, "usd")
+                                if isinstance(price, dict) and cg_id in price:
+                                    ctx["coingecko"] = {"id": cg_id, "price_usd": (price[cg_id] or {}).get("usd")}
+    except Exception:
+        ctx = {}
+
+    _cache_set(key, ctx)
+    return ctx
+
+def realism_ok(comment: str, tweet_text: str) -> bool:
+    """Reject new tickers not in tweet; reject big numbers not in tweet (allow small 1–10)."""
+    if not comment:
+        return False
+    if not tweet_text:
+        return True
+    try:
+        tset = set(_extract_cashtags(tweet_text))
+        cset = set(_extract_cashtags(comment))
+        if not cset.issubset(tset):
+            return False
+
+        tnums = set(_extract_numbers(tweet_text))
+        for n in _extract_numbers(comment):
+            if n in tnums:
+                continue
+            if "." not in n:
+                try:
+                    v = int(n)
+                    if 1 <= v <= 10:
+                        continue
+                except Exception:
+                    pass
+            return False
+        return True
+    except Exception:
+        return True
+
+def _request_context_block() -> str:
+    parts: list[str] = []
+    voice = REQUEST_VOICE.get()
+    if isinstance(voice, dict) and voice.get("id"):
+        parts.append("Voice card:\n- id: %s\n- brief: %s\n- rules: %s\n" % (voice.get("id"), voice.get("brief"), voice.get("rules")))
+    tctx = REQUEST_THREAD_CTX.get()
+    if isinstance(tctx, dict) and tctx:
+        qt = tctx.get("quoted_text") or ""
+        pt = tctx.get("parent_text") or ""
+        if qt or pt:
+            parts.append("Thread/quote context (best-effort):")
+            if qt:
+                parts.append("- quoted_tweet: " + _compact(qt, 520))
+            if pt:
+                parts.append("- parent_tweet: " + _compact(pt, 520))
+            parts.append("")
+    rctx = REQUEST_RESEARCH_CTX.get()
+    if isinstance(rctx, dict) and rctx:
+        parts.append("Project research context (best-effort, may be partial):")
+        try:
+            parts.append(json.dumps(rctx, ensure_ascii=False))
+        except Exception:
+            parts.append(str(rctx))
+        parts.append("")
+    if ENABLE_RESEARCH and not (REQUEST_RESEARCH_CTX.get() or {}):
+        parts.append("If project context is unclear, ask a concrete question instead of making factual claims.")
+    return "\n".join([p for p in parts if p is not None]).strip()
+
+def llm_user_prompt(tweet_text: str, author: str | None) -> str:
+    ctx = _request_context_block()
+    if ctx:
+        return f"Post (author: {author or 'unknown'}):\n{tweet_text}\n\n{ctx}\nReturn exactly two distinct comments (JSON array or two lines)."
+    return f"Post (author: {author or 'unknown'}):\n{tweet_text}\n\nReturn exactly two distinct comments (JSON array or two lines)."
+
+def set_request_context_for_tweet(tweet_text: str, tweet_url: str | None = None) -> None:
+    """Set ContextVars once per request (best-effort; never blocks)."""
+    try:
+        REQUEST_VOICE.set(pick_voice(tweet_text))
+        REQUEST_THREAD_CTX.set(fetch_thread_context(tweet_url) if (ENABLE_THREAD_CONTEXT and tweet_url) else {})
+        REQUEST_RESEARCH_CTX.set(research_context_for_tweet(tweet_text) if ENABLE_RESEARCH else {})
+    except Exception:
+        REQUEST_THREAD_CTX.set({})
+        REQUEST_RESEARCH_CTX.set({})
+        REQUEST_VOICE.set(None)
@@ -136,6 +512,14 @@
 def _do_init() -> None:
     with get_conn() as conn:
         conn.execute("PRAGMA busy_timeout=5000;")
         try:
             conn.execute("PRAGMA journal_mode=WAL;")
         except sqlite3.OperationalError:
             pass
         conn.executescript(
             """
+            CREATE TABLE IF NOT EXISTS entity_map(
+                kind TEXT NOT NULL,
+                k TEXT NOT NULL,
+                slug TEXT NOT NULL,
+                updated_at INTEGER NOT NULL,
+                PRIMARY KEY (kind, k)
+            );
+
             CREATE TABLE IF NOT EXISTS comments (
                 id INTEGER PRIMARY KEY,
                 url TEXT NOT NULL,
@@ -197,10 +581,11 @@
 # ------------------------------------------------------------------------------
 # Tokenization / helpers
 # ------------------------------------------------------------------------------
 
-TOKEN_RE = re.compile(
+WORD_RE = re.compile(
     r"(?:\$\w{2,15}|\d+(?:\.\d+)?|[A-Za-z0-9’']+(?:-[A-Za-z0-9’']+)*)"
 )
+TOKEN_RE = WORD_RE
 
 def _normalize_for_memory(text: str) -> str:
     t = normalize_ws(text).lower()
     t = re.sub(r"[^\w\s']+", " ", t)
     return re.sub(r"\s+", " ", t).strip()
@@ -346,7 +731,7 @@
     return out
 
 def words(text: str) -> list[str]:
-    return TOKEN_RE.findall(text or "")
+    return WORD_RE.findall(text or "")
 
 def style_fingerprint(text: str) -> str:
     """
@@ -1606,6 +1991,10 @@
         # Block repeated sentence skeletons (structure-level repetition)
         if template_burned(c):
             continue
 
+        # Anti-hallucination: no new tickers; no big numbers not in tweet
+        if tweet_text and (not realism_ok(c, tweet_text)):
+            continue
+
         # Keep variants, but avoid exact duplicates
         if c in seen:
             continue
@@ -1778,11 +2167,7 @@
     mode_line = llm_mode_hint(tweet_text)
     sys_prompt = _llm_sys_prompt(mode_line)
 
-    user_prompt = (
-        f"Post (author: {author or 'unknown'}):\n{tweet_text}\n\n"
-        "Return exactly two distinct comments (JSON array or two lines)."
-    )
+    user_prompt = llm_user_prompt(tweet_text, author)
 
     resp = None
     for attempt in range(3):
@@ -1899,11 +2284,7 @@
     if not (USE_OPENAI and _openai_client):
         raise RuntimeError("OpenAI disabled or client not available")
 
-    user_prompt = (
-        f"Post (author: {author or 'unknown'}):\n{tweet_text}\n\n"
-        "Return exactly two distinct comments (JSON array or two lines)."
-    )
+    user_prompt = llm_user_prompt(tweet_text, author)
     mode_line = llm_mode_hint(tweet_text)
     resp = _openai_client.chat.completions.create(
         model=OPENAI_MODEL,
@@ -1926,11 +2307,7 @@
     if not (USE_GEMINI and _gemini_model):
         raise RuntimeError("Gemini disabled or client not available")
 
-    user_prompt = (
-        f"Post (author: {author or 'unknown'}):\n{tweet_text}\n\n"
-        "Return exactly two distinct comments (JSON array or two lines)."
-    )
+    user_prompt = llm_user_prompt(tweet_text, author)
     mode_line = llm_mode_hint(tweet_text)
 
     resp = _gemini_model.generate_content(
@@ -1914,7 +2291,7 @@
 
     out = _ensure_question_punctuation(out)
     if PRO_KOL_POLISH:
         out = pro_kol_polish(out, topic=detect_topic(raw))
-      return out
+    return out
@@ -2077,6 +2454,10 @@
     user_prompt = (
         "Rewrite/regenerate two better comments based on this JSON\n"
         "Use the tweet context. If a project is unclear, ask a good question.\n"
         "JSON:\n" + json.dumps(user_payload, ensure_ascii=False)
     )
+
+    ctx_block = _request_context_block()
+    if ctx_block:
+        user_prompt = user_prompt + "\n\n" + ctx_block
 
     try:
         # Use the first available provider that is already initialized
         if USE_GROQ and _groq_client:
             resp_text = _groq_client.chat.completions.create(
@@ -2348,6 +2729,8 @@
         for url in batch:
             try:
                 t = fetch_tweet_data(url)
 
                 # Prefer handle from upstream payload, fall back to URL parsing
                 handle = t.handle or _extract_handle_from_url(url)
 
+                set_request_context_for_tweet(t.text, tweet_url=url)
+
                 two = generate_two_comments_with_providers(
                     t.text,
                     t.author_name or None,
                     handle,
                     t.lang or None,
                     url=url,
                 )
@@ -2388,6 +2771,8 @@
         t = fetch_tweet_data(url)
         handle = t.handle or _extract_handle_from_url(url)
 
+        set_request_context_for_tweet(t.text, tweet_url=url)
+
         two = generate_two_comments_with_providers(
             t.text,
             t.author_name or None,
             handle,
             t.lang or None,
             url=url,
         )
@@ -2776,0 +3162,0 @@